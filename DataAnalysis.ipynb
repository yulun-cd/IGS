{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from libpysal.weights import Kernel\n",
    "from esda.moran import Moran\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seaborn theme\n",
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf = gpd.read_file('data/AQMS_loc.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the data\n",
    "\n",
    "AQMS_df = pd.read_csv('data/hourly.csv')\n",
    "Rd_gdf = gpd.read_file('data/london_Road.shp')\n",
    "Gsp_gdf = gpd.read_file('data/LD_GreenSpace.shp')\n",
    "cond = pd.read_csv('data/cond_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex loc_gdf and set buffer zones around each site (1km)\n",
    "\n",
    "loc_gdf = loc_gdf.set_index('siteid')\n",
    "loc_gdf['buffer_1km'] = loc_gdf['geometry'].buffer(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rd_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typ in Rd_gdf['function'].unique():\n",
    "    print('Number of ' + typ + ': ', Rd_gdf[Rd_gdf['function'] == typ].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all green spaces\n",
    "Gsp = Gsp_gdf['geometry'].unary_union\n",
    "\n",
    "# Get all types of roads\n",
    "Rd = {}\n",
    "for typ in Rd_gdf['function'].unique():\n",
    "    Rd[typ] = Rd_gdf[Rd_gdf['function'] == typ].loc[:, 'geometry'].unary_union\n",
    "Rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Gsp_gdf, Rd_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf['Gsp'] = loc_gdf['buffer_1km'].intersection(Gsp)\n",
    "for key in Rd.keys():\n",
    "    loc_gdf[key] = loc_gdf['buffer_1km'].intersection(Rd[key])\n",
    "\n",
    "loc_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "loc_gdf.rename(columns={'Restricted Local Access Road': 'RLA_Rd', \n",
    "                        'Minor Road': 'Mi_Rd',\n",
    "                        'A Road': 'A_Rd',\n",
    "                        'Local Road': 'L_Rd',\n",
    "                        'B Road': 'B_Rd',\n",
    "                        'Local Access Road': 'LA_Rd',\n",
    "                        'Secondary Access Road': 'SA_Rd',\n",
    "                        'Motorway': 'Mo_Rd'}, inplace=True)\n",
    "\n",
    "loc_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all near-road green spaces\n",
    "Rd_type = loc_gdf.columns[4:]\n",
    "for col in Rd_type:\n",
    "    loc_gdf['n'+col+'_Gsp'] = loc_gdf['Gsp'].intersection(loc_gdf[col].buffer(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# london boundary read in\n",
    "london = gpd.read_file('data/london_boundary.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise all the sites on the map\n",
    "fig,ax = plt.subplots(1, figsize=(15,13))\n",
    "\n",
    "london.plot(color='lightgrey', ax=ax)\n",
    "loc_gdf['buffer_1km'].plot(color='silver', ax=ax)\n",
    "loc_gdf['geometry'].plot(markersize=10, marker='^', color='blue', \n",
    "                         label='Air quality monitoring site', ax=ax)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "legend=ax.legend(loc='best',shadow=True,fontsize=15)\n",
    "\n",
    "#plt.savefig('sample1.png',facecolor='black',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some buffers that seem to be very close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that specifies the shortest distance of a site to its nearest neighbour\n",
    "loc_gdf['min_dis'] = pd.Series(dtype='float64')\n",
    "for index, row in loc_gdf.iterrows():\n",
    "    dis = []\n",
    "    for i, v in loc_gdf['geometry'].iteritems():\n",
    "        dis.append(row['geometry'].distance(v))\n",
    "    dis.remove(0)\n",
    "    loc_gdf.loc[index, 'min_dis'] = min(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list sites that are close to each other (within 1.5km)\n",
    "loc_gdf[loc_gdf['min_dis']<=1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check their readings' descriptive statistics\n",
    "AQMS_df[AQMS_df['Site'].isin(['BL0', 'CD9', 'GR4', 'GB0'])].groupby('Site').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(AQMS_df[AQMS_df['Site']=='BL0'].Value.values,\n",
    "                AQMS_df[AQMS_df['Site']=='CD9'].Value.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(AQMS_df[AQMS_df['Site']=='GR4'].Value.values,\n",
    "                AQMS_df[AQMS_df['Site']=='GB0'].Value.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both indicate that we should reject H0, meaning the two datasets are statistically significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revmove them from the list\n",
    "#loc_gdf.drop(['BL0','GR4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get areas and edge lengths of green spaces \n",
    "loc_gdf['Gsp_area'] = loc_gdf['Gsp'].area\n",
    "loc_gdf['Gsp_edge'] = loc_gdf['Gsp'].length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get road lengths of each type and nRd gsp area percentages\n",
    "for col in Rd_type:\n",
    "    loc_gdf[col+'_len'] = loc_gdf[col].length\n",
    "    loc_gdf['pct_n'+col+'_Gsp'] = loc_gdf['n'+ col +'_Gsp'].area / loc_gdf['Gsp_area'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf[[col+'_len' for col in Rd_type]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf['Gsp_per_tRd_len'] = loc_gdf['Gsp_area'] / loc_gdf[[col+'_len' for col in Rd_type]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = loc_gdf.columns[21:].tolist()\n",
    "exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge PM reading and site geogemetry data\n",
    "df = pd.merge(AQMS_df, loc_gdf, left_on='Site', right_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "df.drop(['sitename', 'geometry', 'buffer_1km', 'Gsp', 'min_dis'], axis=1, inplace=True)\n",
    "df.drop(Rd_type , axis=1, inplace=True)\n",
    "df.drop(['n'+rd+'_Gsp' for rd in Rd_type], axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with conditional variables\n",
    "df = df.merge(cond, on='ReadingDateTime')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_names = df.columns[-3:].tolist()\n",
    "cond_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[exp_names + cond_names].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporarily save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert the DateTime column to numpy.datetime variable\n",
    "df['ReadingDateTime'] = pd.to_datetime(df['ReadingDateTime'], format=\"%d/%m/%Y %H:%M\")\n",
    "df.rename(columns={'ReadingDateTime':'DateTime'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = df.columns[3:8].tolist()\n",
    "exp_names[1] = 'log_Gsp_area'\n",
    "exp_names[4] = 'log_Gsp_per_Rd_len'\n",
    "exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_names = df.columns[-3:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf = loc_gdf.set_index('siteid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf = pd.merge(df.groupby('Site').mean()[exp_names], loc_gdf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel weight matrix for the sites\n",
    "weight = Kernel.from_dataframe(loc_gdf, geom_col='geometry', function='gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in exp_names:\n",
    "    moran_temp = Moran(loc_gdf[var].values, weight)\n",
    "    print(\"Global Moran's I for \" + var + ' is ', round(moran_temp.I, 5), \n",
    "          ' p-value: ', round(moran_temp.p_norm, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value'].hist(bins=list(range(40)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_Value'] = np.log(df['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_Value'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['DateTime'].dt.hour\n",
    "df.groupby('hour').mean()['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['DateTime'].dt.dayofweek\n",
    "df.groupby('dayofweek').mean()['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofmonth'] = df['DateTime'].dt.day\n",
    "df.groupby('dayofmonth').mean()['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Value'] + exp_names + cond_names].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(100-df['rh_mean']), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.normaltest(np.log(100-df['rh_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(reg, features, target, feature_names, rep=50, method='r2'):\n",
    "    mean = []\n",
    "    std = []\n",
    "    importance = permutation_importance(reg, features, target, n_repeats=rep,\n",
    "                                        random_state=25, scoring=method)\n",
    "    for i in range(len(feature_names)):\n",
    "        mean.append(round(importance.importances_mean[i], 5))\n",
    "        std.append(round(importance.importances_std[i], 5))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(reg, features, target, iter=100, split=10, method='r2'):\n",
    "    score = []\n",
    "    for i in range(iter):\n",
    "        kf = KFold(n_splits=split, shuffle=True, random_state=i)\n",
    "        cv = cross_val_score(reg, features, target, cv=kf, scoring=method).tolist()\n",
    "        score = score + cv\n",
    "    \n",
    "    return (np.mean(score), np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "var = exp_names + cond_names\n",
    "\n",
    "ap_X = df[var].values\n",
    "ap_y = df['Value'].values\n",
    "\n",
    "reg.fit(ap_X, ap_y)\n",
    "\n",
    "get_importance(reg, ap_X, ap_y, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_score(reg, ap_X, ap_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['hour']==0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran = []\n",
    "for time in df['DateTime'].unique():\n",
    "    moran_temp = Moran(df[df['DateTime']==time].Value.values, weight)\n",
    "    moran.append([round(moran_temp.I, 5), round(moran_temp.p_norm, 5)])\n",
    "moran_df = pd.DataFrame(df['DateTime'].unique(), columns=['DateTime'])\n",
    "moran_df[['moran', 'p-value']] = moran\n",
    "moran_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_df['hour']= moran_df['DateTime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4, 6, figsize=(24,16))\n",
    "i = 0\n",
    "for hour in range(24):\n",
    "    sns.lineplot(x=moran_df['DateTime'].dt.date.unique(), \n",
    "                 y=moran_df[moran_df['hour']==hour].moran.values, \n",
    "                 ax=ax[i//6, i%6], linewidth=1)\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_fi = []\n",
    "h_cv = []\n",
    "h_coef = []\n",
    "for hour in df['hour'].unique():\n",
    "    X = df[df['hour']==hour].loc[:,var].values\n",
    "    y = df[df['hour']==hour].loc[:,'Value'].values\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    fi_mean, fi_std = get_importance(reg, X, y, feature_names=var)\n",
    "    h_fi.append(fi_mean + fi_std)\n",
    "    \n",
    "    r2 = list(get_cv_score(reg, X, y))\n",
    "    mse = list(get_cv_score(reg, X, y, method='neg_mean_squared_error'))\n",
    "    h_cv.append(r2 + mse)\n",
    "    \n",
    "    coef = reg.coef_.tolist()\n",
    "    coef.append(reg.intercept_)\n",
    "    h_coef.append(coef)\n",
    "    \n",
    "h_fi = pd.DataFrame(h_fi, columns=['fi_' + elem for elem in var] + ['fi_std_' + elem for elem in var])\n",
    "h_cv = pd.DataFrame(h_cv, columns=['r2', 'r2_std', 'mse', 'mse_std'])\n",
    "h_coef = pd.DataFrame(h_coef, columns=var+['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_reg = pd.concat([h_coef, h_cv, h_fi], axis=1)\n",
    "h_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6, figsize=(24, 16))\n",
    "i = 0\n",
    "for hour in range(24):\n",
    "    g = sns.barplot(x=['fi_' + elem for elem in var], y=h_reg.loc[hour, ['fi_' + elem for elem in var]],\n",
    "                    ax=ax[i//6, i%6])\n",
    "    g.set(xticklabels=[])\n",
    "    i += 1\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a new column for month information\n",
    "df['month'] = df['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_df['month'] = moran_df['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3, 4, figsize=(16,12))\n",
    "i = 0\n",
    "for month in range(1,13):\n",
    "    sns.lineplot(x='DateTime', y='moran', data=moran_df[moran_df['month']==month],\n",
    "                 ax=ax[i//4, i%4], linewidth=1)\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_fi = []\n",
    "m_cv = []\n",
    "m_coef = []\n",
    "for month in df['month'].unique():\n",
    "    X = df[df['month']==month].loc[:, var].values\n",
    "    y = df[df['month']==month].loc[:, 'Value'].values\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    fi_mean, fi_std = get_importance(reg, X, y, feature_names=var)\n",
    "    m_fi.append(fi_mean + fi_std)\n",
    "    \n",
    "    r2 = list(get_cv_score(reg, X, y))\n",
    "    mse = list(get_cv_score(reg, X, y, method='neg_mean_squared_error'))\n",
    "    m_cv.append(r2 + mse)\n",
    "    \n",
    "    coef = reg.coef_.tolist()\n",
    "    coef.append(reg.intercept_)\n",
    "    m_coef.append(coef)\n",
    "    \n",
    "m_fi = pd.DataFrame(m_fi, columns=['fi_' + elem for elem in var] + ['fi_std_' + elem for elem in var])\n",
    "m_cv = pd.DataFrame(m_cv, columns=['r2', 'r2_std', 'mse', 'mse_std'])\n",
    "m_coef = pd.DataFrame(m_coef, columns=var+['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_reg = pd.concat([m_coef, m_cv, m_fi], axis=1)\n",
    "m_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, figsize=(16, 12))\n",
    "i = 0\n",
    "for month in range(1,13):\n",
    "    g = sns.barplot(x=['fi_' + elem for elem in var], y=m_reg.loc[month-1, ['fi_' + elem for elem in var]],\n",
    "                    ax=ax[i//4, i%4])\n",
    "    g.set(xticklabels=[])\n",
    "    i += 1\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('month').mean()['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_period = df[df['month'].isin([1, 2, 3, 4])].drop(['geometry','hour','dayofweek','dayofmonth','month'],axis=1)\n",
    "low_period = df[~df['month'].isin([1, 2, 3, 4])].drop(['geometry','hour','dayofweek','dayofmonth','month'],axis=1)\n",
    "\n",
    "print('high period: '+str(high_period.shape)+'\\nlow period: '+str(low_period.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_X = high_period[var].values\n",
    "hp_y = high_period['Value'].values\n",
    "reg.fit(hp_X, hp_y)\n",
    "\n",
    "get_importance(reg, hp_X, hp_y, feature_names=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_score(reg, hp_X, hp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_.tolist() + [reg.intercept_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_X = low_period[var].values\n",
    "lp_y = low_period['Value'].values\n",
    "reg.fit(lp_X, lp_y)\n",
    "\n",
    "get_importance(reg, lp_X, lp_y, feature_names=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_score(reg, lp_X, lp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_.tolist() + [reg.intercept_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_df = df.groupby(['hour','Site']).mean()\n",
    "hmean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_df.drop(['bp_mean','tmp_mean','rh_mean','dayofweek','dayofmonth'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(hmean_df[['Value']+exp_names].corr().round(4),annot=True,fmt='.4f',cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(df,iter_range,method='pearson',features=exp_names,target='Value'):\n",
    "    result=[]\n",
    "    for index in iter_range:\n",
    "        result.append(df.loc[(index,)].corr(method=method).loc[features,target])\n",
    "    result=np.asarray(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moran(df,iter_range,w=weight,target='Value'):\n",
    "    result=[]\n",
    "    for index in iter_range:\n",
    "        result.append(Moran(df.loc[(index,),target].values,w).I)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_info(df,iter_range,features=exp_names,target='Value',reg=LinearRegression()):\n",
    "    result=[]\n",
    "    for index in iter_range:\n",
    "        x=df.loc[(index,),features].values\n",
    "        #x=(x-np.mean(x,axis=0))/np.std(x,axis=0)\n",
    "        \n",
    "        y=df.loc[(index,),target].values\n",
    "        #y=(y-np.mean(y,axis=0))/np.std(y,axis=0)\n",
    "        \n",
    "        reg.fit(x,y)\n",
    "        coef=reg.coef_.tolist()\n",
    "        coef.append(reg.score(x,y))\n",
    "        result.append(coef)\n",
    "    result=pd.DataFrame(result,columns=features+['score'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_corr=get_corr(hmean_df,range(24))\n",
    "sns.lineplot(data=hmean_corr,legend=False)\n",
    "plt.legend(labels=exp_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_corr_sp=get_corr(hmean_df,range(24),method='spearman')\n",
    "sns.lineplot(data=hmean_corr_sp,legend=False)\n",
    "plt.legend(labels=exp_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_moran=get_moran(hmean_df,range(24))\n",
    "sns.lineplot(x=range(24),y=hmean_moran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean_reg=get_reg_info(hmean_df,range(24))\n",
    "sns.lineplot(x=range(24),y=hmean_reg['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot monthly mean\n",
    "df.groupby('month').mean()['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmean_df=df.groupby(['month','Site']).mean()\n",
    "mmean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmean_corr=get_corr(mmean_df,range(1,13))\n",
    "sns.lineplot(data=mmean_corr,legend=False)\n",
    "plt.legend(labels=exp_names,loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmean_corr_sp=get_corr(mmean_df,range(1,13),method='spearman')\n",
    "sns.lineplot(data=mmean_corr_sp,legend=False)\n",
    "plt.legend(labels=exp_names,loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmean_moran=get_moran(mmean_df,range(1,13))\n",
    "sns.lineplot(x=range(1,13),y=mmean_moran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmean_reg=get_reg_info(mmean_df,range(1,13))\n",
    "sns.lineplot(x=range(1,13),y=mmean_reg['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify high period and low period\n",
    "high=df[df['month'].isin([1,2,3,4])].groupby('Site').mean()\n",
    "low=df[~df['month'].isin([1,2,3,4])].groupby('Site').mean()\n",
    "\n",
    "print('high: '+str(high.shape)+'\\nlow: '+str(low.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(high[['Value']+exp_names].corr().round(4),annot=True,fmt='.4f',cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_moran=Moran(high['Value'].values,weight)\n",
    "round(high_moran.I,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_high=LinearRegression()\n",
    "y_high = high['Value'].values\n",
    "x_high = high[exp_names].values\n",
    "reg_high.fit(x_high, y_high)\n",
    "reg_high.score(x_high,y_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_high = reg_high.predict(x_high)\n",
    "\n",
    "r = stats.pearsonr(y_high, prd_high)[0]\n",
    "r2 = r**2\n",
    "t, p_value = stats.kendalltau(y_high, prd_high)\n",
    "print('r2 (obs): ', round(r2, 5))\n",
    "print('tau (obs): ', round(t, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2_high = []\n",
    "cv_tau_high = []\n",
    "\n",
    "for i in range(100):\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    cvprd_high = cross_val_predict(reg_high, x_high, y_high, cv=kf)  #predict using current random folds\n",
    "    \n",
    "    #correlations\n",
    "    r = stats.pearsonr(y_high,cvprd_high)[0]\n",
    "    t, p_value = stats.kendalltau(y_high, prd_high)\n",
    "    \n",
    "    #append to list\n",
    "    cv_r2_high.append(r**2)\n",
    "    cv_tau_high.append(t)\n",
    "\n",
    "print('r2 (cv): ', round(np.mean(cv_r2_high), 5))\n",
    "print('tau (cv): ', round(np.mean(cv_tau_high),5))\n",
    "print('r2 variance (cv): ', 1.96 * np.var(cv_r2_high))\n",
    "print('tau variance (cv): ', 1.96 * np.var(cv_tau_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(low[['Value']+exp_names].corr().round(4),annot=True,fmt='.4f',cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_moran=Moran(low['Value'].values,weight)\n",
    "round(low_moran.I,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_low = LinearRegression()\n",
    "y_low = low['Value'].values\n",
    "x_low = low[exp_names].values\n",
    "reg_low.fit(x_low, y_low)\n",
    "prd_low = reg_low.predict(x_low)\n",
    "\n",
    "r = low['Value'].corr(pd.Series(prd_low))\n",
    "r2 = r**2\n",
    "t = low['Value'].corr(pd.Series(prd_low), method='kendall')\n",
    "print(\"r2 (cv): \", round(r2,3))   \n",
    "print(\"tau (cv): \", round(t,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(all[['Value']+exp_names].corr().round(4),annot=True,fmt='.4f',cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=df.groupby('Site').mean()\n",
    "all_moran=Moran(all['Value'].values,weight)\n",
    "round(all_moran.I,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all=(all.groupby('Site').mean()['Value'].values)\n",
    "x_all=(all.groupby('Site').mean()[exp_names].values)\n",
    "\n",
    "reg.fit(x_all,y_all)\n",
    "reg.score(x_all,y_all)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "203d01a3458eace725dddcfcdb2c604435d077f4f6685c100707a5d3f77ea293"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('sds2021': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
